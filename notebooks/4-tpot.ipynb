{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "from pathlib import Path\n",
    "\n",
    "#  always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.imports import *\n",
    "from src.data.download_data import *\n",
    "from src.data.fire_data import *\n",
    "from src.data.read_data import *\n",
    "from src.gen_functions import *\n",
    "from src.features.build_features import *\n",
    "from src.visualization.visualize import *\n",
    "import seaborn as sns\n",
    "output_notebook()\n",
    "# set font size \n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "from datetime import timedelta\n",
    "from matplotlib.ticker import MaxNLocator# transition from acceptable to unhealthy for sensitive group and to unhealthy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition from acceptable to unhealthy for sensitive group and to unhealthy. \n",
    "transition_dict = { 'PM2.5': [0, 35.5, 55.4, 1e3],\n",
    "                  'PM10': [0, 155, 254, 1e3],\n",
    "                  'O3':[0, 70 , 85, 1e3],\n",
    "                  'SO2':[0, 75, 185, 1e3],\n",
    "                  'NO2': [0, 100, 360, 1e3],\n",
    "                  'CO': [0, 6.4, 12.5, 1e3]}\n",
    "\n",
    "gas_list = ['PM2.5', 'PM10', 'O3', 'CO', 'NO2', 'SO2']\n",
    "\n",
    "city_info = {'Country': 'Thailand',\n",
    " 'City': 'Chiang Mai',\n",
    " 'City (ASCII)': 'Chiang Mai',\n",
    " 'Region': 'Chiang Mai',\n",
    " 'Region (ASCII)': 'Chiang Mai',\n",
    " 'Population': '200952',\n",
    " 'Latitude': '18.7904',\n",
    " 'Longitude': '98.9847',\n",
    " 'Time Zone': 'Asia/Bangkok'}\n",
    "\n",
    "city_name = city_info['City'].lower().replace(' ', '_')\n",
    "\n",
    "x = merc_x(city_info['Longitude'])\n",
    "y = merc_y(city_info['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_folder='../data/pm25/'\n",
    "a4th_folder ='../data/air4thai_hourly/'\n",
    "cm_folder ='../data/cm_proc/'\n",
    "cdc_folder = '../data/cdc_data/'\n",
    "aqm_folder = '../data/aqm_hourly2/'\n",
    "model_folder = f'../models/{city_name}/'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5'], dtype='object')\n",
      "(168337, 8)\n",
      "(165459, 13)\n"
     ]
    }
   ],
   "source": [
    "aqm1 = pd.read_csv(cm_folder + '35t.csv').set_index('datetime').dropna(how='all')\n",
    "aqm1.index = pd.to_datetime(aqm1.index)\n",
    "aqm2 = pd.read_csv(cm_folder + '36t.csv').set_index('datetime').dropna(how='all')\n",
    "aqm2.index = pd.to_datetime(aqm2.index)\n",
    "print(aqm2.columns)\n",
    "# keep only the data after the satallite data which is 200-11-11 13 am\n",
    "aqm2_01 = aqm2[aqm2.index>='2000-11-01 00:00:00'].copy()\n",
    "aqm2_01 = add_season(aqm2_01)\n",
    "print(aqm2_01.shape)\n",
    "\n",
    "# weather data \n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/Mueang_Chiang_Mai.csv'\n",
    "wea = pd.read_csv(filename)\n",
    "wea.drop(['Time','Dew Point(C)','Wind Gust(kmph)','Pressure(in)','Precip.(in)'], axis=1, inplace=True)\n",
    "wea['datetime'] = pd.to_datetime(wea['datetime'])\n",
    "# merge with weather \n",
    "\n",
    "aqm2_01 = aqm2_01.merge(wea, left_index=True, right_on ='datetime',how='inner').set_index('datetime')\n",
    "print(aqm2_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>lat_km</th>\n",
       "      <th>long_km</th>\n",
       "      <th>distance</th>\n",
       "      <th>power</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-07-04 13:03:00</th>\n",
       "      <td>67</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>11453.0</td>\n",
       "      <td>665.551109</td>\n",
       "      <td>120.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-04 13:04:00</th>\n",
       "      <td>52</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>11701.0</td>\n",
       "      <td>694.254989</td>\n",
       "      <td>20.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-04 13:04:00</th>\n",
       "      <td>48</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>11682.0</td>\n",
       "      <td>689.069015</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-04 13:04:00</th>\n",
       "      <td>91</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>11682.0</td>\n",
       "      <td>689.341767</td>\n",
       "      <td>132.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-04 13:05:00</th>\n",
       "      <td>62</td>\n",
       "      <td>2428.0</td>\n",
       "      <td>11936.0</td>\n",
       "      <td>968.527252</td>\n",
       "      <td>10.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     confidence  lat_km  long_km    distance   power  count\n",
       "datetime                                                                   \n",
       "2002-07-04 13:03:00          67  1612.0  11453.0  665.551109  120.96      1\n",
       "2002-07-04 13:04:00          52  2246.0  11701.0  694.254989   20.52      1\n",
       "2002-07-04 13:04:00          48  2304.0  11682.0  689.069015   13.50      1\n",
       "2002-07-04 13:04:00          91  2305.0  11682.0  689.341767  132.30      1\n",
       "2002-07-04 13:05:00          62  2428.0  11936.0  968.527252   10.45      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m_proc.csv')\n",
    "fire['datetime'] = pd.to_datetime(fire['datetime'])\n",
    "fire = fire.set_index('datetime')\n",
    "fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for feature eng fire\n",
    "def cal_power_damp(series: pd.core.series.Series, distance: pd.core.series.Series, surface='sphere'):\n",
    "    \"\"\" Calculate the damped power based on the distance series. \n",
    "\n",
    "    The damping factor maybe 1/distance or 1/distance**2.\n",
    "    Args: \n",
    "        series: series to recalculate\n",
    "        distance: distance array. Must have the same lenght as the series\n",
    "        surface(optional): either 'circle' or 'sphere'\n",
    "\n",
    "    Returns:\n",
    "        new_series\n",
    "\n",
    "    Examples:\n",
    "        cal_power_damp(fire['power'], fire['distance'],surface='sphere')\n",
    "\n",
    "    \"\"\"\n",
    "    if surface == 'sphere':\n",
    "        new_series = series/distance**2\n",
    "\n",
    "    elif surface == 'circle':\n",
    "        new_series = series/distance\n",
    "\n",
    "    return new_series\n",
    "\n",
    "\n",
    "def cal_arrival_time(detection_time: pd.core.series.Series, distance: pd.core.series.Series, wind_speed: (float, np.array) = 2):\n",
    "    \"\"\" Calculate the approximate time that the pollution arrived at the city using the wind speed and distance from the hotspot.\n",
    "\n",
    "    Round arrival time to hour \n",
    "\n",
    "    Args:\n",
    "        detection_time: datetime series\n",
    "        distance: distance series in km\n",
    "        wind_speed(optional): approximate wind speed, can be floar or array in km/hour\n",
    "\n",
    "    Returns: \n",
    "        arrival_time: datetime series of arrival time\n",
    "\n",
    "    \"\"\"\n",
    "    arrival_time = detection_time + pd.to_timedelta(distance/wind_speed, 'h')\n",
    "    return arrival_time.dt.round('H')\n",
    "\n",
    "\n",
    "def shift_fire(fire_df: pd.core.frame.DataFrame, fire_col: str = 'power', damp_surface: str = 'sphere', shift: int = 0, roll: int = 48, w_speed: (float, int) = 8):\n",
    "    \"\"\" Feature engineer fire data. Account of the distance from the source and time lag using wind speed.\n",
    "\n",
    "    Args:\n",
    "        fire_df:\n",
    "        fire_col\n",
    "        damp_surface\n",
    "        shift\n",
    "        roll\n",
    "\n",
    "    \"\"\"\n",
    "    require_cols = ['distance', fire_col]\n",
    "    if fire_df.columns.isin(require_cols).sum() > len(require_cols):\n",
    "        raise AssertionError(\n",
    "            'missing required columns for feature engineering fire data')\n",
    "\n",
    "    # calculate the damping factors\n",
    "    fire_df['damp_'+fire_col] = cal_power_damp(\n",
    "        fire_df[fire_col], fire_df['distance'], surface=damp_surface)\n",
    "    # calculate particle arrival time\n",
    "    fire_df['arrival_time'] = cal_arrival_time(\n",
    "        detection_time=fire_df.index, distance=fire_df['distance'], wind_speed=w_speed)\n",
    "    fire_df = fire_df.set_index('arrival_time')\n",
    "    fire_df = fire_df.resample('h').sum()['damp_'+fire_col]\n",
    "    fire_df = fire_df.rolling(roll).sum()\n",
    "    fire_df = fire_df.shift(shift)\n",
    "    fire_df.index.name = 'datetime'\n",
    "    return fire_df\n",
    "\n",
    "\n",
    "def get_fire_feature(fire, zone_list=[0, 100, 200, 400, 800, 1000], fire_col: str = 'power', damp_surface: str = 'sphere', shift: int = 0, roll: int = 48, w_speed: (float, int) = 8):\n",
    "    \"\"\" Separate fire from different distance\n",
    "\n",
    "    \"\"\"\n",
    "    fire_col_list = []\n",
    "    new_fire = pd.DataFrame()\n",
    "    for start, stop in zip(zone_list, zone_list[1:]):\n",
    "        col_name = f'fire_{start}_{stop}'\n",
    "\n",
    "        fire_col_list.append(col_name)\n",
    "        # select sub-data baseline the distance\n",
    "        fire_s = fire[(fire['distance'] < stop) & (fire['distance'] >= start)][[fire_col, 'distance']].copy()\n",
    "        fire_s = shift_fire(fire_s, fire_col=fire_col, damp_surface=damp_surface,\n",
    "                            shift=shift, roll=roll, w_speed=w_speed)\n",
    "        fire_s.name = col_name\n",
    "        new_fire = pd.concat([new_fire, fire_s], axis=1, ignore_index=False)\n",
    "\n",
    "    new_fire = new_fire.fillna(0)\n",
    "    return new_fire, fire_col_list\n",
    "\n",
    "def sep_fire_zone(fire, fire_col, zone_list=[0, 100, 200, 400, 800, 1000]):\n",
    "    \"\"\" Separate fire data into zone mark by a distance in the zone_list without perform feature enginering.\n",
    "    Use for data visualization\n",
    "    \n",
    "    Args: \n",
    "        fire: fire dataframe\n",
    "        fire_col: 'power' or 'count'\n",
    "        zone_list:\n",
    "        \n",
    "    Return: \n",
    "        new_fire: a dataframe with each column, a fire data in that zone\n",
    "        fire_col_list: a list of column name\n",
    "    \n",
    "    \"\"\"\n",
    "    fire_col_list = []\n",
    "    new_fire = pd.DataFrame()\n",
    "    for start, stop in zip(zone_list, zone_list[1:]):\n",
    "        col_name = f'fire_{start}_{stop}'\n",
    "        fire_col_list.append(col_name)\n",
    "        # select sub-data baseline the distance\n",
    "        fire_s = fire[(fire['distance'] < stop) & (fire['distance'] >= start)][[fire_col]].copy()\n",
    "        fire_s.columns = [col_name]\n",
    "        fire_s = fire_s.resample('h').sum()\n",
    "        new_fire = pd.concat([new_fire, fire_s], axis=1, ignore_index=False)\n",
    "\n",
    "    return new_fire, fire_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_dict = {'fire_col': 'power',\n",
    " 'surface': 'sphere',\n",
    " 'w_speed': 10,\n",
    " 'shift': -24,\n",
    " 'roll': 72}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_index(data_index, shuffle=False,val_size=0.3, test_size=0.25):\n",
    "    trn, test = train_test_split(data_index, test_size=test_size, shuffle=False)\n",
    "    trn, val  = train_test_split(trn, test_size=val_size, shuffle=False)\n",
    "    print('train size', len(trn))\n",
    "    print('validation size',len(val))\n",
    "    print('test size',len(test))\n",
    "    return trn,  val, test\n",
    "\n",
    "def get_data_matrix(data, pollutant,use_index, x_cols=[]):\n",
    "    \"\"\"Extract data in data dataframe into x,y matricies using use_index.\n",
    "    \n",
    "    \"\"\"\n",
    "    temp = data.loc[use_index]\n",
    "    \n",
    "    y = temp[pollutant].values\n",
    "    \n",
    "    if len(x_cols)==0:\n",
    "        x = temp.drop(pollutant,axis=1)\n",
    "    else:\n",
    "        x = temp[x_cols]\n",
    "        \n",
    "    x_cols = x.columns\n",
    "    return x.values, y, x_cols\n",
    "\n",
    "# Add AutoRegressive Feature\n",
    "\n",
    "# calculate number of lag \n",
    "def find_num_lag(poll_series, thres=0.5):\n",
    "    \"\"\" Calculate the numbers of partial autocorrelation lag to add as feature to a time series. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pac = pacf(poll_series)\n",
    "    # find the number of lag \n",
    "    idxs = np.where(pac >= 0.5)[0]\n",
    "    return idxs[1:]\n",
    "\n",
    "def add_lags(data, pollutant):\n",
    "    \"\"\"Add lags columns to x_data.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate num lags\n",
    "    num_lags = find_num_lag(data[pollutant])\n",
    "    for idx in num_lags:\n",
    "        lag_name = f'{pollutant}_lag_{idx}'\n",
    "        lag_series = data[pollutant].shift(idx) \n",
    "        lag_series.name = lag_name\n",
    "        # add to data \n",
    "        data = pd.concat([data, lag_series], axis=1) \n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and keep only relavant data \n",
    "pollutant = 'PM2.5'\n",
    "cols = [pollutant, 'Temperature(C)', 'Humidity(%)', 'Wind', 'Wind Speed(kmph)', 'Condition']\n",
    "data = aqm2_01[cols].dropna()\n",
    "\n",
    "if pollutant == 'PM2.5':\n",
    "    data = data.loc['2010':]\n",
    "\n",
    "# add weather \n",
    "dummies = wind_to_dummies(data['Wind'])\n",
    "data.drop('Wind',axis=1, inplace=True)\n",
    "data = pd.concat([data, dummies], axis=1)\n",
    "data = add_is_rain(data)\n",
    "data = add_calendar_info(data)\n",
    "data = add_lags(data, pollutant)\n",
    "data_no_fire = data.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 31401\n",
      "validation size 20935\n",
      "test size 22431\n"
     ]
    }
   ],
   "source": [
    "# split data index \n",
    "# because will be building new feature later in the pipeline, therefore only need index here.\n",
    "trn_idx, val_idx, test_idx = split_data_index(data.index,shuffle=False, val_size=0.4, test_size=0.3)\n",
    "# split furture for rf \n",
    "trn_rf_idx, val_rf_idx = train_test_split(trn_idx,test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the best parameters \n",
    "fire_col = fire_dict['fire_col']\n",
    "w_speed = fire_dict['w_speed']\n",
    "damp_surface = fire_dict['surface']\n",
    "shift = fire_dict['shift']\n",
    "roll = fire_dict['roll']\n",
    "# obtain fire data \n",
    "fire_proc, fire_col_list = get_fire_feature(fire, zone_list=[0, 100, 200, 400, 800, 1000], \n",
    "fire_col=fire_col,damp_surface=damp_surface, \n",
    "shift=shift, roll=roll, w_speed=w_speed)\n",
    " \n",
    "# merge fire data \n",
    "data = data_no_fire.merge(fire_proc, left_index=True, right_index=True, how='inner')\n",
    "data = data.dropna()\n",
    " \n",
    "x_cols = ['Wind Speed(kmph)', 'Temperature(C)', 'Humidity(%)', 'time_of_day',\n",
    "       'fire_400_800', 'fire_800_1000', 'fire_200_400', 'fire_0_100',\n",
    "       'fire_100_200', 'PM2.5_lag_1']\n",
    "xtrn, ytrn, x_cols = get_data_matrix(data, pollutant,trn_idx, x_cols=x_cols)\n",
    "xval, yval, _ = get_data_matrix(data, pollutant,val_idx, x_cols=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=300.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -118.70543593428506\n",
      "Generation 2 - Current best internal CV score: -118.70543593428506\n",
      "Generation 3 - Current best internal CV score: -118.70543593428506\n",
      "Generation 4 - Current best internal CV score: -118.70543593428506\n",
      "Generation 5 - Current best internal CV score: -118.70543593428506\n",
      "Best pipeline: XGBRegressor(AdaBoostRegressor(input_matrix, learning_rate=0.01, loss=linear, n_estimators=100), learning_rate=0.1, max_depth=3, min_child_weight=13, n_estimators=100, nthread=1, objective=reg:squarederror, subsample=0.7000000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "              disable_update_check=False, early_stop=None, generations=5,\n",
       "              log_file=<ipykernel.iostream.OutStream object at 0x00000189E2DF4088>,\n",
       "              max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "              mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "              periodic_checkpoint_folder=None, population_size=50,\n",
       "              random_state=None, scoring=None, subsample=1.0, template=None,\n",
       "              use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ask TPOT to hunt for the best model\n",
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2)\n",
    "tpot.fit(xtrn, ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-62.410713640603696\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(xval,yval))\n",
    "tpot.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
