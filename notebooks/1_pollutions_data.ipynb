{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Source\" data-toc-modified-id=\"Data-Source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Source</a></span></li><li><span><a href=\"#Imports-and-Update-The-Latest-Data\" data-toc-modified-id=\"Imports-and-Update-The-Latest-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports and Update The Latest Data</a></span></li><li><span><a href=\"#Historical-air-4-Thai-Data\" data-toc-modified-id=\"Historical-air-4-Thai-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Historical air 4 Thai Data</a></span></li><li><span><a href=\"#Power-Plants\" data-toc-modified-id=\"Power-Plants-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Power Plants</a></span></li><li><span><a href=\"#Weather-Files\" data-toc-modified-id=\"Weather-Files-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Weather Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fill-the-missing-value-in-Weather-Data\" data-toc-modified-id=\"Fill-the-missing-value-in-Weather-Data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Fill the missing value in Weather Data</a></span></li></ul></li><li><span><a href=\"#Holiday-In-Thailand\" data-toc-modified-id=\"Holiday-In-Thailand-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Holiday In Thailand</a></span></li><li><span><a href=\"#Hotspots-Data\" data-toc-modified-id=\"Hotspots-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hotspots Data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source \n",
    "1. Berekely Earth 'http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/'\n",
    "2. Screaped Air4Thai Data 'http://air4thai.pcd.go.th/webV2/history/'\n",
    "3. CDC Data 'https://www.cmuccdc.org/download_json/'\n",
    "4. Old Air4Thai data from Thailand EPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Update The Latest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "from pathlib import Path\n",
    "\n",
    "#  always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.imports import *\n",
    "from src.data.download_data import *\n",
    "from src.data.read_data import *\n",
    "from src.data.dl_weather import *\n",
    "from src.gen_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_folder='../data/pm25/'\n",
    "a4th_folder='../data/air4thai_hourly/'\n",
    "cdc_folder = '../data/cdc_data/'\n",
    "aqm_folder = '../data/aqm_hourly2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 801033 / 801033"
     ]
    }
   ],
   "source": [
    "# Data from Berkeley Earth Projects: \n",
    "download_b_data(data_folder='../data/pm25/', url='http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/')\n",
    "get_city_info(data_folder='../data/pm25/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stations 407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 404/404 [14:53<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "download_cdc_data(station_url='https://www.cmuccdc.org/api/ccdc/stations', \n",
    "                  dl_url= 'https://www.cmuccdc.org/download_json/', \n",
    "                  data_folder='../data/cdc_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [29:49, 22.10s/it]\n"
     ]
    }
   ],
   "source": [
    "update_last_air4Thai(url='http://air4thai.pcd.go.th/webV2/history/',data_folder='../data/air4thai_hourly/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical air 4 Thai Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "124\n",
      "125\n",
      "['35t', '36t', 'm9']\n"
     ]
    }
   ],
   "source": [
    "# load stations information\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "# find stations in Chiangmai and parase that files\n",
    "cm_station_ids = []\n",
    "for i, stations in enumerate(station_info):\n",
    "    if 'Chiang Mai' in stations['areaEN']:\n",
    "        # ignore station that start with o\n",
    "        if 'o' not in stations['stationID']:\n",
    "            cm_station_ids.append(stations['stationID'])\n",
    "            print(i)\n",
    "print(cm_station_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save filename ../data/aqm_hourly2/process/35t.csv\n",
      "save filename ../data/aqm_hourly2/process/36t.csv\n"
     ]
    }
   ],
   "source": [
    "# parase historical data \n",
    "for station_id in cm_station_ids:\n",
    "    # find all files that start with this stations\n",
    "    p = Path(aqm_folder)\n",
    "    filenames = []\n",
    "    for i in p.glob('**/*.xlsx'):\n",
    "        if station_id in i.name:\n",
    "            filenames.append(str(i))\n",
    "        \n",
    "    # if filename exist load that file\n",
    "    if len(filenames) >0:\n",
    "\n",
    "        save_filename = aqm_folder + 'process/' + station_id + '.csv'\n",
    "        print('save filename', save_filename)\n",
    "        station_data = read_his_xl(filenames[0])\n",
    "        #print(station_data.head())\n",
    "\n",
    "        # save the data if the dataframe is not empty\n",
    "        if len(station_data)> 0:\n",
    "            station_data.to_csv(save_filename,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data1 = pd.read_csv(aqm_folder + 'process/35t.csv')\n",
    "cm_data1['datetime'] = pd.to_datetime(cm_data1['datetime'])\n",
    "cm_data1 = cm_data1.set_index('datetime')\n",
    "# keep only gas columns\n",
    "cm_data1 = cm_data1[['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5']]\n",
    "\n",
    "cm_data2 = pd.read_csv(aqm_folder + 'process/36t.csv')\n",
    "cm_data2['datetime'] = pd.to_datetime(cm_data2['datetime'])\n",
    "cm_data2 = cm_data2.set_index('datetime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://th.wikipedia.org/wiki/%E0%B8%A3%E0%B8%B2%E0%B8%A2%E0%B8%8A%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B9%82%E0%B8%A3%E0%B8%87%E0%B9%84%E0%B8%9F%E0%B8%9F%E0%B9%89%E0%B8%B2%E0%B9%83%E0%B8%99%E0%B9%84%E0%B8%97%E0%B8%A2'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_power_stations_in_Thailand'\n",
    "table_list = pd.read_html(url)\n",
    "len(table_list)\n",
    "p_folder = '../data/power_plants/'\n",
    "for i, table in enumerate(table_list):\n",
    "    table.to_csv(p_folder + f'table_eng{i}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\bkk\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\chiang-mai\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\chiang-rai\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\kungming\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\luang-prabang\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\sikhottabong\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\tada_u\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\tak\\\\',\n",
       " 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities\\\\yangong\\\\']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/*/')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkk 13\n",
      "chiang-mai 36\n",
      "chiang-rai 25\n",
      "kungming 24\n",
      "luang-prabang 24\n",
      "sikhottabong 39\n",
      "tada_u 24\n",
      "tak 26\n",
      "yangong 29\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    city_name = Path(folder).name\n",
    "    parent_folder = Path(folder).parent\n",
    "    w_files = glob(folder + '/*.csv')\n",
    "    print(city_name, len(w_files))\n",
    "    filename = str(Path(folders[0]).parent) + '/' + city_name + '.csv'\n",
    "    \n",
    "    # concatenate all files \n",
    "    df_all = pd.DataFrame()\n",
    "    for file in w_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    \n",
    "    # drop missing value \n",
    "    df_all['datetime'] = pd.to_datetime(df_all['date'])\n",
    "    df_all.drop('date',axis=1, inplace=True)\n",
    "    df_all = df_all.sort_values('datetime')\n",
    "    df_all = df_all.drop_duplicates('datetime', ignore_index=True)\n",
    "    \n",
    "    # save file\n",
    "    df_all.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing date for chiang-mai data \n",
    "df_all = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv')\n",
    "df_all['datetime'] = pd.to_datetime(df_all['datetime'] )\n",
    "# find exisiting date \n",
    "ex_date = df_all['datetime'].dt.strftime('%Y-%m-%d').unique()\n",
    "ex_date = set(ex_date)\n",
    "# calculate the datelist \n",
    "start_date = datetime(2000, 10, 1)\n",
    "stop_date = datetime.now()\n",
    "date_range = pd.date_range(start_date, stop_date).strftime('%Y-%m-%d')\n",
    "missing_date = list(set(date_range).difference(ex_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'Mueang Chiang Mai', 'province': 'Chiang Mai', 'country': 'Thailand', 'station_name': 'Chiang Mai International Airport Station', 'specific_url': 'th/mueang-chiang-mai/', 'latitude': '18.8 °N', 'longitude': '98.97 °E'}\n"
     ]
    }
   ],
   "source": [
    "with open('../data/weather_cities/weather_station_info.json','r') as f:\n",
    "    station_dict_list = json.load(f)\n",
    "   \n",
    "i = 0 \n",
    "city_json = station_dict_list[i]\n",
    "print(city_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/mueang-chiang-mai_weather.csv 2000-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\src\\data\\dl_weather.py:20: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 20 of the file ..\\src\\data\\dl_weather.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(innerhtml)\n"
     ]
    }
   ],
   "source": [
    " bad_date_df = scrape_weather(city_json, date_range=missing_date, data_folder='C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fill the missing value in Weather Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333126, 11)\n"
     ]
    }
   ],
   "source": [
    "# weather data \n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv'\n",
    "wea = pd.read_csv(filename)\n",
    "wea['datetime']  = pd.to_datetime(wea['datetime'])\n",
    "# roud datetiem to whole 30 mins \n",
    "wea['datetime'] = wea['datetime'].dt.round('30T')\n",
    "\n",
    "dates = wea['datetime'].dropna().dt.date.unique()\n",
    "\n",
    "# fill in the missing value\n",
    "new_datetime = pd.date_range(start=dates[0], end=dates[-1], freq='30T') \n",
    "new_weather = pd.DataFrame(new_datetime, columns=['datetime'])\n",
    "new_weather = new_weather.merge(wea, on='datetime',how='left')\n",
    "print(new_weather.shape)\n",
    "\n",
    "# remove strange T reading\n",
    "lowest_t = 5 \n",
    "idx = new_weather[new_weather['Temperature(C)']< lowest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "highest_t = 60\n",
    "idx = new_weather[new_weather['Temperature(C)']> highest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "new_weather = new_weather.fillna(method='ffill',limit=12)\n",
    "new_weather = new_weather.fillna(method='bfill',limit=12)\n",
    "new_weather = new_weather.set_index('datetime')\n",
    "new_weather = new_weather.dropna(how='all').reset_index()\n",
    "new_weather.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holiday In Thailand\n",
    "\n",
    "https://www.timeanddate.com/holidays/thailand/2001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotspots Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stationID': '36t', 'nameTH': 'โรงเรียนยุพราชวิทยาลัย ', 'nameEN': 'Yupparaj Wittayalai School', 'areaTH': 'ต.ศรีภูมิ อ.เมือง, เชียงใหม่', 'areaEN': 'Si Phum, Meuang, Chiang Mai', 'stationType': 'GROUND', 'lat': '18.7909205', 'long': '98.9881062', 'LastUpdate': {'date': '2020-03-27', 'time': '03:00', 'PM25': {'value': '87', 'unit': 'µg/m³'}, 'PM10': {'value': '110', 'unit': 'µg/m³'}, 'O3': {'value': 'N/A', 'unit': 'ppb'}, 'CO': {'value': '1.09', 'unit': 'ppm'}, 'NO2': {'value': '-', 'unit': 'ppb'}, 'SO2': {'value': '2', 'unit': 'ppb'}, 'AQI': {'Level': '4', 'aqi': '192'}}}\n"
     ]
    }
   ],
   "source": [
    "# load stations information for Chiangmai\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "print(station_info[124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117.0 11019.0\n"
     ]
    }
   ],
   "source": [
    "# obtain the lat and long in km\n",
    "lat_km = (merc_y(station_info[124]['lat'])/1E3 ).round()\n",
    "long_km = (merc_x(station_info[124]['long'])/1E3).round()\n",
    "print(lat_km,  long_km )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file map folder \n",
    "m_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6/*.csv')\n",
    "v_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/V1/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4772188, 15)\n",
      "(214976, 17)\n",
      "column length 17\n",
      "(4461419, 15)\n",
      "(235249, 17)\n",
      "column length 17\n",
      "(4248841, 15)\n",
      "(229176, 17)\n",
      "column length 17\n",
      "(4983109, 15)\n",
      "(234913, 17)\n",
      "column length 17\n",
      "(4723105, 15)\n",
      "(165272, 17)\n",
      "column length 17\n",
      "(4742107, 15)\n",
      "(288160, 17)\n",
      "column length 17\n",
      "(4488383, 15)\n",
      "(230523, 17)\n",
      "column length 17\n",
      "(4855536, 15)\n",
      "(176189, 17)\n",
      "column length 17\n",
      "(5172627, 15)\n",
      "(276734, 17)\n",
      "column length 17\n",
      "(4721882, 15)\n",
      "(198856, 17)\n",
      "column length 17\n",
      "(5158284, 15)\n",
      "(225431, 17)\n",
      "column length 17\n",
      "(5127336, 15)\n",
      "(276406, 17)\n",
      "column length 17\n",
      "(5184272, 15)\n",
      "(195966, 17)\n",
      "column length 17\n",
      "(3726003, 15)\n",
      "(45055, 17)\n",
      "column length 17\n",
      "(185960, 15)\n",
      "(7802, 17)\n",
      "column length 17\n",
      "(264718, 15)\n",
      "(2898, 17)\n",
      "column length 17\n",
      "(4314389, 15)\n",
      "(210563, 17)\n",
      "column length 17\n",
      "(4443358, 15)\n",
      "(198697, 17)\n",
      "column length 17\n",
      "(4478281, 15)\n",
      "(142868, 17)\n",
      "column length 17\n",
      "(4210218, 15)\n",
      "(149221, 17)\n",
      "column length 17\n",
      "(1392967, 14)\n",
      "(196963, 16)\n",
      "column length 16\n"
     ]
    }
   ],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "shape = 0\n",
    "\n",
    "for file in m_files:\n",
    "    f = pd.read_csv(file)\n",
    "    print(f.shape)\n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round()\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round()\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "    \n",
    "    print(f.shape)\n",
    "    \n",
    "    shape = shape + f.shape[0]\n",
    "    print('column length', len(f.columns))\n",
    "    if os.path.exists(filename):\n",
    "        f.to_csv(filename, header=None, mode='a', index=False)\n",
    "    else:\n",
    "        f.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected shape  3901918\n",
      "(3901918, 17)\n"
     ]
    }
   ],
   "source": [
    "print('expected shape ', shape)\n",
    "df = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21393656, 14)\n",
      "(1100046, 16)\n",
      "column length 16\n",
      "(20097731, 14)\n",
      "(1177369, 16)\n",
      "column length 16\n",
      "(19319890, 14)\n",
      "(1142863, 16)\n",
      "column length 16\n",
      "(20826285, 14)\n",
      "(969884, 16)\n",
      "column length 16\n",
      "(16633347, 14)\n",
      "(1039761, 16)\n",
      "column length 16\n",
      "(20299549, 14)\n",
      "(1099041, 16)\n",
      "column length 16\n",
      "(19996363, 14)\n",
      "(751954, 16)\n",
      "column length 16\n",
      "(19131468, 14)\n",
      "(751741, 16)\n",
      "column length 16\n",
      "(5180494, 14)\n",
      "(851508, 16)\n",
      "column length 16\n",
      "(1350471, 14)\n",
      "(208055, 16)\n",
      "column length 16\n",
      "final shape 9092222\n"
     ]
    }
   ],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv'\n",
    "shape = 0\n",
    "\n",
    "for file in v_files:\n",
    "    f = pd.read_csv(file)\n",
    "    print(f.shape)\n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round()\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round()\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "    \n",
    "    print(f.shape)\n",
    "    \n",
    "    shape = shape + f.shape[0]\n",
    "    print('column length', len(f.columns))\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        f.to_csv(filename, header=None, mode='a', index=False)\n",
    "    else:\n",
    "        f.to_csv(filename, index=False)\n",
    "        \n",
    "print('final shape', shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092222, 16)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
